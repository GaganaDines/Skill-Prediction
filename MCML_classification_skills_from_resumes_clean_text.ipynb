{"cells":[{"cell_type":"markdown","source":["#### Installing the required libraries"],"metadata":{"id":"EKAqQsSIS9ps"}},{"cell_type":"code","source":["!pip install transformers datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csolO1vLS2kW","outputId":"5c77a3f7-82d4-450f-cb02-318712834337"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: tokenizers, safetensors, xxhash, dill, multiprocess, huggingface-hub, transformers, datasets\n","Successfully installed datasets-2.14.4 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0 xxhash-3.3.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"TcbfT-y57WIG"},"source":["### Importing necessaries libraries..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6UFTz9nc-efD"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import os\n","import sys\n","\n","import numpy as np\n","import random as rn\n","import pandas as pd\n","import re\n","from bs4 import BeautifulSoup\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","import torch\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import TrainingArguments, Trainer\n","from transformers import EvalPrediction\n","from datasets import load_dataset\n","\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from ast import literal_eval\n","from sklearn.metrics import f1_score, roc_auc_score, accuracy_score"]},{"cell_type":"markdown","metadata":{"id":"teAgxrOKSrqG"},"source":["#### Important Parameters\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruLH1HDsSrqG"},"outputs":[],"source":["MAX_LENGTH = 512\n","BATCH_SIZE = 8 #the higher is better but requires more memory\n","EPOCHS = 5 #the higher is better but requires more time to complete the training process\n","THRESHOLD = 0.5\n","METRIC_NAME = \"f1\""]},{"cell_type":"markdown","metadata":{"id":"aO2hQXYuGy9A"},"source":["#### Setting up data path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9hDIgZyGM0K","tags":[]},"outputs":[],"source":["#root_data_path = '/content/drive/MyDrive/Colab Notebooks/cv_splits_csv'\n","\n","root_data_path = '/content/drive/MyDrive/ColabNotebooks/MSc-dissertation/skill-prediction/preprocess/data/cv_splits_csv'\n","#root_data_path = '/projets/sig/mullah/nlp/cv/data/corpus_splits/'\n","\n","#root_data_dir = '/projets/sig/mullah/nlp/cv/models' (create )\n","root_data_dir = '/content/drive/MyDrive/ColabNotebooks/MSc-dissertation/skill-prediction/models'"]},{"cell_type":"markdown","metadata":{"id":"OaV9c8IuSrqH"},"source":["#### Loading train, validation, and test datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["3a6880c292384ef59f8e227d40b00e42","229db6941ed349dbbd4b9c20b3faf607","38ac85ce52d941e5b602a3a1656d7e1f","32e7ba06884d4e5589b702e73f57fcaf","74e68d04a30d4b939ac20d3fc51f4696","9a323efd600c4f2ba59cd8c8c7141a95","fab6cfa3afbf49dfba3922d3ea3425f3","f53c5708f3e34e46a714557c2e5eb4fe","56c8caab6d3b4a81a8e4cebe01ce63a6","c3e986a9588c4ef39b672d8cf69e498d","0b68c6c126c447759efd632a8a53e337","b57716a3f500442b921a5e7171be91a9","9c6a7688e1f641a1b57806b1bfc4185f","07ec3ee1e08a42019bff34e50ec2a8fb","b6e750d57d0a4bcc8dada03052c70073","ec700bbf04dd49729dda87dc06960899","708ee297d08342a8a7875bb234fbebbf","441162e58b7f4933aecec48b7f62bfad","9351e0894d61487d94fc1ed6c7a8addd","4e623707c6964a83a3b4aa58fb80f5ce","63d787e019044b78b566b10253cbd5ac","b9c7e816ea414cf99bc47c9f10098c9b","a14f0e4c81b14ff9bc84759d6d42e6d4","5ae7e6bab912491f8616a96b8090858f","ee734698a67d4fb5ba1db56eb55e7f41","bbac0075b6b040e6b1756a0e409e461b","51c34cfd104e4d8f8b53f076ecc0b1e1","d5f976b04f0d4a4a8b412530a738043a","8e207d86bc5c4826a71c55fd8f4a1090","073e4f9f6189407cb80c0f759b7a787b","ab0a4a85926b41cbbc750f92288b46cf","28d46a3b50e843729974fdadb93048c0","a4b96b1e7c794bdeb2039cd23c5cafd3"],"base_uri":"https://localhost:8080/","height":538},"id":"2KukGbRGSrqI","outputId":"200d1211-7a86-417f-92a1-61cf35615634"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a6880c292384ef59f8e227d40b00e42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b57716a3f500442b921a5e7171be91a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a14f0e4c81b14ff9bc84759d6d42e6d4"}},"metadata":{}},{"output_type":"error","ename":"DatasetGenerationError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSchemaInferenceError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[1;32m   1948\u001b[0m                 \u001b[0mnum_shards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshard_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1949\u001b[0;31m                 \u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self, close_stream)\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mSchemaInferenceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please pass `features` or at least one example when writing data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         logger.debug(\n","\u001b[0;31mSchemaInferenceError\u001b[0m: Please pass `features` or at least one example when writing data","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-c5c5c2d96773>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#print (data_files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[0;31m# Download and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[1;32m   2137\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                             \u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_proc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                         self._download_and_prepare(\n\u001b[0m\u001b[1;32m    955\u001b[0m                             \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m                             \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                 \u001b[0;31m# Prepare split will record examples associated to the split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 raise OSError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_prepare_split\u001b[0;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[1;32m   1811\u001b[0m             \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m                 for job_id, done, content in self._prepare_split_single(\n\u001b[0m\u001b[1;32m   1814\u001b[0m                     \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_prepare_split_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m                 ):\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSchemaInferenceError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__context__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m                 \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDatasetGenerationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"An error occurred while generating the dataset\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_num_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_num_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"]}],"source":["data_files = {\n","    \"train\": os.path.join(root_data_path, \"train.csv\"),\n","    \"validation\": os.path.join(root_data_path, \"val.csv\"),\n","    \"test\": os.path.join(root_data_path, \"test.csv\")\n","}\n","#print (data_files)\n","\n","dataset = load_dataset('csv', data_files = data_files)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLZ7BFXvSrqJ","outputId":"02036ce8-9b2e-4b63-cbb5-9c9671e07afb"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Id', 'Text', 'Tags'],\n","        num_rows: 17870\n","    })\n","    validation: Dataset({\n","        features: ['Id', 'Text', 'Tags'],\n","        num_rows: 5957\n","    })\n","    test: Dataset({\n","        features: ['Id', 'Text', 'Tags'],\n","        num_rows: 5956\n","    })\n","})"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"markdown","metadata":{"id":"iE-qPzpP7cEF"},"source":["#### Initializing random seed values to stabilize the outcomes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqdQ7gWJHRYb"},"outputs":[],"source":["rn.seed(321)\n","np.random.seed(321)\n","torch.manual_seed(321)\n","torch.cuda.manual_seed(321)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R8Z8cMwGSrqK","outputId":"3a0a4d64-9e6e-46db-c9da-0255046c843f"},"outputs":[{"data":{"text/plain":["[\"['Software_Developer']\",\n"," \"['Network_Administrator']\",\n"," \"['Project_manager']\",\n"," \"['Web_Developer', 'Software_Developer']\",\n"," \"['Web_Developer', 'Software_Developer', 'Front_End_Developer']\"]"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["dataset['train']['Tags'][:5]"]},{"cell_type":"markdown","metadata":{"id":"nuZwc0L8SrqK"},"source":["Two critical problems here: </br>\n"," **Multiple labels** for each sample</br>\n"," **Labels** are in string of list format</br>\n","We have to solve these two problems, convert the string of list to list format and binarized the multilabel of samples"]},{"cell_type":"markdown","metadata":{"id":"DJP_8r1TSrqK"},"source":["#### Encoding labels of train, validation, and test set\n","**Converting** string of list to list using *literal_eval* function. </br>\n","Using MultiLabelBinarizer to encode the multiclass multilabel target\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"noJiilxfSrqL"},"outputs":[],"source":["train_labels = [literal_eval(labels) for labels in dataset['train']['Tags']]\n","validation_labels = [literal_eval(labels) for labels in dataset['validation']['Tags']]\n","test_labels = [literal_eval(labels) for labels in dataset['test']['Tags']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"isxf5or_SrqL","outputId":"2148d2cc-908e-4c66-9817-26bc16be49ab"},"outputs":[{"data":{"text/plain":["[['Software_Developer'],\n"," ['Network_Administrator'],\n"," ['Project_manager'],\n"," ['Web_Developer', 'Software_Developer'],\n"," ['Web_Developer', 'Software_Developer', 'Front_End_Developer']]"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["train_labels[:5]"]},{"cell_type":"markdown","metadata":{"id":"TYUcBz-6SrqL"},"source":["Fitting the _MultiLabelBinarizer_ on the train subset labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZxyBjh5uSrqL","outputId":"f4265770-ebef-4aec-df77-2b7ba9fb78da"},"outputs":[{"data":{"text/plain":["MultiLabelBinarizer()"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["multilabel_binarizer = MultiLabelBinarizer()\n","multilabel_binarizer.fit(train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z2n1SVE7SrqL","outputId":"6dc7f407-c4aa-47fc-a9c4-8196e71dbfa2"},"outputs":[{"data":{"text/plain":["array(['Database_Administrator', 'Front_End_Developer', 'Java_Developer',\n","       'Network_Administrator', 'Project_manager', 'Python_Developer',\n","       'Security_Analyst', 'Software_Developer', 'Systems_Administrator',\n","       'Web_Developer'], dtype=object)"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["multilabel_binarizer.classes_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MHmTHO32SrqM","outputId":"b6ef3c74-6907-488b-978c-27f7afd37dd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels:  ['Database_Administrator' 'Front_End_Developer' 'Java_Developer'\n"," 'Network_Administrator' 'Project_manager' 'Python_Developer'\n"," 'Security_Analyst' 'Software_Developer' 'Systems_Administrator'\n"," 'Web_Developer']\n","Id2Labels:  {0: 'Database_Administrator', 1: 'Front_End_Developer', 2: 'Java_Developer', 3: 'Network_Administrator', 4: 'Project_manager', 5: 'Python_Developer', 6: 'Security_Analyst', 7: 'Software_Developer', 8: 'Systems_Administrator', 9: 'Web_Developer'}\n","Labels2Id:  {'Database_Administrator': 0, 'Front_End_Developer': 1, 'Java_Developer': 2, 'Network_Administrator': 3, 'Project_manager': 4, 'Python_Developer': 5, 'Security_Analyst': 6, 'Software_Developer': 7, 'Systems_Administrator': 8, 'Web_Developer': 9}\n"]}],"source":["labels = multilabel_binarizer.classes_\n","print (\"Labels: \", labels)\n","id2label = {idx:label for idx, label in enumerate(labels)}\n","print (\"Id2Labels: \", id2label)\n","label2id = {id2label.get(idx):idx for idx in id2label}\n","print (\"Labels2Id: \", label2id)"]},{"cell_type":"markdown","metadata":{"id":"rNFv8w_oSrqM"},"source":["#### Preprocess data (Encoding)\n","BERT doesn't expect text as direct input, but rather text encoding in terms of *input_ids*, *attention masks*, etc. We tokenise the text using the BERT's tokenizer (**AutoTokenizer** API from Huggingface)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyuKmB50SrqM"},"outputs":[],"source":["lemmatizer = WordNetLemmatizer()\n","\n","def clean_resume_text( raw_text ):\n","    '''\n","        cleaning html tags, non-alphanumeric symbol, stop words from the given text\n","    '''\n","    escaped_text = BeautifulSoup(raw_text).get_text()\n","    alphanum_text = re.sub(\"[^a-zA-Z0-9]\", \" \", escaped_text)\n","    alphanum_lower_text = alphanum_text.lower()\n","\n","    #Tokenize text into words\n","    words = word_tokenize(alphanum_lower_text)\n","\n","    #Remove stop words\n","    stop_words = set(stopwords.words('english'))\n","    filtered_words = [word for word in words if word not in stop_words]\n","\n","    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n","    preprocessed_text = ' '.join( lemmatized_words )\n","\n","    return preprocessed_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yuhdajCmSrqM","outputId":"995a1f11-c461-4f5b-a64a-4e5135203008"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /users/sig/mullah/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /users/sig/mullah/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /users/sig/mullah/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /users/sig/mullah/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /users/sig/mullah/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","def preprocess_data(examples):\n","    #take a batch of texts\n","    texts = examples['Text']\n","\n","    clean_texts= [clean_resume_text(text) for text in texts]\n","\n","    #encode them\n","    encoding = tokenizer(clean_texts, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n","\n","    #add labels\n","    tags = examples['Tags']\n","    tags_label = [literal_eval(tag) for tag in tags]\n","    tags_label_binarizer = np.array(multilabel_binarizer.transform(tags_label), dtype=np.float32)\n","\n","    encoding['labels'] = tags_label_binarizer.tolist()\n","\n","    #labels_batch = {k:examples[k] for k in examples.keys() if k in labels}\n","    #transform labels_batch dictionary to numpy arrays\n","    #labels_matrix = np.zeros((len(texts), len(labels)))\n","    #for idx, label in enumerate(labels):\n","    #    labels_matrix[:, idx] = labels_batch[label]\n","    #encoding[\"labels\"] = labels_matrix.tolist()\n","\n","\n","    return encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["7ebbb1d4dc804d0bbdcfe228b65b3fa4","2dc5df8aaf914dfd85dc78691fe0d9c5","90950d5255644defa0abc2bd467e68f2"]},"id":"TU7BJH-eSrqM","outputId":"3f72ba48-0450-4032-bc5c-9287589e3344"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ebbb1d4dc804d0bbdcfe228b65b3fa4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/18 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2dc5df8aaf914dfd85dc78691fe0d9c5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90950d5255644defa0abc2bd467e68f2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"US1FHlvgSrqN","outputId":"7aa67312-3f26-4b9d-ea02-5e8e9ba8f798"},"outputs":[{"data":{"text/plain":["dict_keys(['train', 'validation', 'test'])"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["encoded_dataset.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CgRluKPFSrqN"},"outputs":[],"source":["check_idx = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTiwOME9SrqN","outputId":"ec481f9e-3089-4b74-9cf3-14af1224b551"},"outputs":[{"data":{"text/plain":["512"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["example = encoded_dataset['train'][check_idx]['input_ids']\n","len(example)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WScdlPC-SrqN","outputId":"7e3e0dd9-644a-403d-90cd-67b9b20d241d"},"outputs":[{"data":{"text/plain":["'[CLS] network administratoir network administratoir network administrator bergquist company river fall wi network experience lan wan window nt 2000 2003 2008r2 managed switch extreme network hp procurve san dell equallogic emc vnx na qnap ad dhcp dns win network monitoring solarwinds netflow avaya voip shoretel voip siemens voip router firewall vpn cisco asa watchguard sonicwall nsa tz series application experience m application primarily m office 97 2013 solidworks autocad epicor vantage corvu backup exec arcserver dp backup veeam blackberry server dreamweaver operating system experience m do window 3 1 95 98 nt w 2000 pro xp pro home vista 7 window server nt 2000 2003 2008 2012 exchange server 5 5 2000 2003 redhat centos suse vmware esx 3 5 vsphere 4 x 5 x programming experience basic c html work experience network administratoir bergquist company chanhassen mn march 2014 present responsibility maintain wan connection three site setup maintain 100 window 2003 2008 2012 server setup maintain vmware esx 5 1 vsphere 5 1 8 host server maintain equallogic san emc vnx 5300 san sans connectivity via iscsi fiber channel maintain two cisco ucs blade center maintain exchange 2003 server create delete maintain email account backup information store maintain office 365 maintain office vpn connectivity cisco asas manages user account 1000 user manages nightly backup veeam backup exec vaultlogix software managed siemens voip phone system provide help desk desktop support function hardware software provide instruction application software primarily m office troubleshooting software hardware printer problem manage negotiate consultant vendor telecommunication service network administrator health service management woodbury mn march 2012 present maintain wan connection three site setup maintain 40 window 2000 2003 2008 server setup maintain 4 linux redhat centos server setup maintain vmware esx 5 0 vsphere 5 0 4 host server setup maintain 2 equallogic sans consolidation elimination 13 server converted virtual server maintains exchange 2003 server create delete maintain email account backup information store setup maintain office vpn connectivity sonicwall client manages user account 40 user manages nightly backup veeam backup exec software manage symantec anti virus sql maintenance user permission backup restore database managed installation shoretel voip phone system managed installation security system provide help desk desktop support function hardware software provide instruction application software primarily m office troubleshooting software hardware printer problem manage negotiate consultant vendor telecommunication service network administrator hirel system march 2007 present setup maintains wan connection ten office setup maintains 50 window 2000 2003 [SEP]'"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(example)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_nu0NNPYSrqN","outputId":"a46b6de1-981b-40ad-a8c8-92a7585d9504"},"outputs":[{"data":{"text/plain":["tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["encoded_dataset['train'][check_idx]['labels']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zm4ilmSlSrqN","outputId":"2ffae2e8-8917-4daa-cca7-6b0eb87bc61a"},"outputs":[{"data":{"text/plain":["array(['Database_Administrator', 'Front_End_Developer', 'Java_Developer',\n","       'Network_Administrator', 'Project_manager', 'Python_Developer',\n","       'Security_Analyst', 'Software_Developer', 'Systems_Administrator',\n","       'Web_Developer'], dtype=object)"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yj-ghKsXSrqO","outputId":"57998fd1-ceec-4ed3-8eee-8259573ae095"},"outputs":[{"data":{"text/plain":["['Network_Administrator']"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["[id2label.get(idx) for idx, label in enumerate(encoded_dataset['train'][check_idx]['labels']) if label == 1.0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWvZsyQ2SrqO"},"outputs":[],"source":["encoded_dataset.set_format(\"torch\")"]},{"cell_type":"markdown","metadata":{"id":"jSifMC-nJ6Em"},"source":["### Multi-label Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTr1OhlRSrqO","outputId":"f95c0e3e-f82a-4a7f-a533-ba142d994da1"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /users/sig/mullah/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"Database_Administrator\",\n","    \"1\": \"Front_End_Developer\",\n","    \"2\": \"Java_Developer\",\n","    \"3\": \"Network_Administrator\",\n","    \"4\": \"Project_manager\",\n","    \"5\": \"Python_Developer\",\n","    \"6\": \"Security_Analyst\",\n","    \"7\": \"Software_Developer\",\n","    \"8\": \"Systems_Administrator\",\n","    \"9\": \"Web_Developer\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"Database_Administrator\": 0,\n","    \"Front_End_Developer\": 1,\n","    \"Java_Developer\": 2,\n","    \"Network_Administrator\": 3,\n","    \"Project_manager\": 4,\n","    \"Python_Developer\": 5,\n","    \"Security_Analyst\": 6,\n","    \"Software_Developer\": 7,\n","    \"Systems_Administrator\": 8,\n","    \"Web_Developer\": 9\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /users/sig/mullah/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                          problem_type=\"multi_label_classification\",\n","                                                          num_labels = len(labels),\n","                                                          id2label = id2label,\n","                                                          label2id = label2id)"]},{"cell_type":"markdown","metadata":{"id":"wKa3WXt_SrqO"},"source":["#### Setting up the Training Arguments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ReOe6cKtSrqO","outputId":"3eee6a12-7982-49fc-91ed-029f333ba9a6"},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["args = TrainingArguments(\n","    os.path.join(root_data_dir, f\"mcml_bert-finetuned-skills-prediction-clean-data\"),\n","    overwrite_output_dir = True,\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate = 2e-5,\n","    per_device_train_batch_size = BATCH_SIZE,\n","    per_device_eval_batch_size = BATCH_SIZE,\n","    num_train_epochs = EPOCHS,\n","    weight_decay = 0.01,\n","    load_best_model_at_end = True,\n","    metric_for_best_model = METRIC_NAME\n",")"]},{"cell_type":"markdown","metadata":{"id":"rE1yY3TuSrqO"},"source":["#### Computing Multi-label Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0fZDMnWSrqO"},"outputs":[],"source":["def multi_label_metrics(predictions, labels, threshold=0.5):\n","    #applying sigmoid on the prediction (batch_size, num_labels)\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(predictions))\n","\n","    #threshold to turn them into integer predictions (like class id)\n","    y_pred = np.zeros(probs.shape)\n","    y_pred[np.where(probs>=threshold)] = 1\n","\n","    #compute metrics\n","    y_true = labels\n","    f1_micro_average = f1_score(y_true = y_true, y_pred = y_pred, average='micro')\n","    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n","    accuracy = accuracy_score(y_true, y_pred)\n","\n","    metrics_score = {\n","            'f1' : f1_micro_average,\n","            'roc_auc'  : roc_auc,\n","            'accuracy' : accuracy}\n","    return metrics_score\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n","    result = multi_label_metrics(predictions = preds, labels = p.label_ids)\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"FyVpPbGeSrqP"},"source":["Let's verify a batch as well as a forward pass:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cer39exkSrqV","outputId":"7bf69b62-9f1e-4084-f9b3-da4c48b65155"},"outputs":[{"data":{"text/plain":["tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["encoded_dataset['train'][0]['labels'].unsqueeze(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i5NvDSR6SrqV","outputId":"39dd46ef-ffd8-4cae-aaed-c75f9ecbc4f3"},"outputs":[{"data":{"text/plain":["tensor([[  101,  3169,  3208,  3169,  3208, 11577, 18712,  9362,  2147,  1057,\n","         11194,  2147,  3325,  3169,  3208, 27589,  4974,  9117, 11775, 12982,\n","         18712,  2233,  2760,  2556, 22834,  4087,  8619, 19429, 24997,  2102,\n","         14521, 18712,  2251,  2418,  2233,  2760,  2622, 10669,  5843,  7159,\n","         14521, 18712,  2254,  2418,  2238,  2418,  3698,  6872, 26680, 17655,\n","          2194,  6701,  2821,  2254,  2355,  2254,  2418,  2503,  5096,  2966,\n","          5949,  2326,  4937, 20897,  9695, 18712,  2257,  2325,  2254,  2355,\n","          4012, 23041,  5555,  4263, 18558, 28472, 16364,  1059,  2615,  2089,\n","          2325,  2257,  2325, 27166,  2278, 24532,  5498,  3367,  7829, 10669,\n","          3212,  2504,  2028,  3435, 24454, 16364,  1059,  2615,  2257,  2297,\n","          2089,  2325, 25718,  9722,  3353,  2490, 21929,  7520, 21405,  2986,\n","          2396,  3916,  2811,  2286,  2297,  2495,  2152,  2082,  9827,  8066,\n","          7513,  2436,  1019,  2095, 25718,  1019,  2095, 24970,  1019,  2095,\n","          2630, 16550,  3752,  1016,  2095,  4807,  1016,  2095,  5814,  1016,\n","          2095,  4730,  1019,  2095, 22834,  1019,  2095,  2622, 12016,  1015,\n","          2095,  4957,  8299,  7479,  5799,  2378,  4012,  6337,  3193,  8909,\n","          4090,  2683, 23833, 19317, 12521,  3176,  2592,  2247,  2627,  2783,\n","          6107,  7714,  2448,  4773,  2640,  5821,  2194, 19416,  3815,  7396,\n","           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]])"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["encoded_dataset['train'][0]['input_ids'].unsqueeze(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Kzh2evwSrqV","outputId":"89040a90-19bc-4a72-9969-b9746f4bf2ff"},"outputs":[{"data":{"text/plain":["SequenceClassifierOutput(loss=tensor(0.8332, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-0.2531,  0.5737, -0.1311,  0.2489, -0.0673,  0.8570,  0.2247, -0.8437,\n","         -0.2123,  0.2131]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"execution_count":97,"metadata":{},"output_type":"execute_result"}],"source":["#forward pass\n","outputs = model(input_ids=encoded_dataset['train'][0]['input_ids'].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n","outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwNfSpJpSrqW","outputId":"0015e813-9dd0-44cc-b5cd-1f39c22fd593"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([10])\n"]}],"source":["outputs.logits.squeeze().cpu()\n","print (torch.nn.Sigmoid()(outputs.logits.squeeze().cpu()).shape)"]},{"cell_type":"markdown","metadata":{"id":"CR6qKm4RSrqW"},"source":["#### Training the models\n","Let's start training the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"69n1dCZsSrqW"},"outputs":[],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset = encoded_dataset[\"train\"],\n","    eval_dataset = encoded_dataset[\"validation\"],\n","    tokenizer = tokenizer,\n","    compute_metrics = compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PhIEyB-SrqW","outputId":"5fa7f052-fd34-460d-bf25-7721a20559cb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/users/sig/mullah/.conda/envs/e36t11/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 17870\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 11170\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='8937' max='11170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 8937/11170 1:12:32 < 18:07, 2.05 it/s, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","      <th>Roc Auc</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.111300</td>\n","      <td>0.104182</td>\n","      <td>0.907939</td>\n","      <td>0.934101</td>\n","      <td>0.744334</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.086200</td>\n","      <td>0.094103</td>\n","      <td>0.912367</td>\n","      <td>0.945863</td>\n","      <td>0.749203</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.069000</td>\n","      <td>0.086300</td>\n","      <td>0.922374</td>\n","      <td>0.944197</td>\n","      <td>0.781937</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='311' max='745' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [311/745 00:46 < 01:04, 6.70 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 5957\n","  Batch size = 8\n","Saving model checkpoint to /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-2234\n","Configuration saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-2234/config.json\n","Model weights saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-2234/pytorch_model.bin\n","tokenizer config file saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-2234/tokenizer_config.json\n","Special tokens file saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-2234/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 5957\n","  Batch size = 8\n","Saving model checkpoint to /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-4468\n","Configuration saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-4468/config.json\n","Model weights saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-4468/pytorch_model.bin\n","tokenizer config file saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-4468/tokenizer_config.json\n","Special tokens file saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-4468/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 5957\n","  Batch size = 8\n","Saving model checkpoint to /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-6702\n","Configuration saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-6702/config.json\n","Model weights saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-6702/pytorch_model.bin\n","tokenizer config file saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-6702/tokenizer_config.json\n","Special tokens file saved in /projets/sig/mullah/nlp/cv/models/mcml_bert-finetuned-skills-prediction-clean-data/checkpoint-6702/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 5957\n","  Batch size = 8\n","IOPub message rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_msg_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}],"source":["#launching the trainer\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"ZyX2tfMUSrqW"},"source":["#### Evaluate on the train set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_JetG2xSSrqW","outputId":"2b7138f1-cb98-417c-8f27-c5ace8370de8"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running Prediction *****\n","  Num examples = 17870\n","  Batch size = 8\n"]}],"source":["predictions_train = trainer.predict(\n","    test_dataset=encoded_dataset['train']\n",")"]},{"cell_type":"markdown","metadata":{"id":"6b00KDUXSrqX"},"source":["#### Evaluate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQKZj7X8SrqX","outputId":"6771c797-5186-4d6b-afcc-b851f1d0c425"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 5957\n","  Batch size = 8\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3724' max='745' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [745/745 29:47]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.08639294654130936,\n"," 'eval_f1': 0.9231722428748451,\n"," 'eval_roc_auc': 0.9479516307770601,\n"," 'eval_accuracy': 0.7842873929830452,\n"," 'eval_runtime': 110.6472,\n"," 'eval_samples_per_second': 53.838,\n"," 'eval_steps_per_second': 6.733,\n"," 'epoch': 5.0}"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"H46fnysdSrqX"},"source":["#### Predictions on test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iORd3cHDSrqX","outputId":"0b98fca4-c684-4eca-f9c8-3222a6f5309c"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running Prediction *****\n","  Num examples = 5956\n","  Batch size = 8\n"]}],"source":["predictions = trainer.predict(\n","    test_dataset=encoded_dataset['test']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51q3BkxISrqX","outputId":"207da556-f6fe-4262-c19a-e5d93691d61b"},"outputs":[{"data":{"text/plain":["{'test_loss': 0.08285614848136902,\n"," 'test_f1': 0.9277367040305271,\n"," 'test_roc_auc': 0.9509022786745007,\n"," 'test_accuracy': 0.7960040295500336,\n"," 'test_runtime': 111.2222,\n"," 'test_samples_per_second': 53.55,\n"," 'test_steps_per_second': 6.698}"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["predictions.metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzil2vtWSrqX"},"outputs":[],"source":["#re-run the experiments for number of tokens 512 (instead of 128)"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Py36 (torch)","language":"python","name":"e36t11"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3a6880c292384ef59f8e227d40b00e42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_229db6941ed349dbbd4b9c20b3faf607","IPY_MODEL_38ac85ce52d941e5b602a3a1656d7e1f","IPY_MODEL_32e7ba06884d4e5589b702e73f57fcaf"],"layout":"IPY_MODEL_74e68d04a30d4b939ac20d3fc51f4696"}},"229db6941ed349dbbd4b9c20b3faf607":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a323efd600c4f2ba59cd8c8c7141a95","placeholder":"​","style":"IPY_MODEL_fab6cfa3afbf49dfba3922d3ea3425f3","value":"Downloading data files: 100%"}},"38ac85ce52d941e5b602a3a1656d7e1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f53c5708f3e34e46a714557c2e5eb4fe","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56c8caab6d3b4a81a8e4cebe01ce63a6","value":3}},"32e7ba06884d4e5589b702e73f57fcaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3e986a9588c4ef39b672d8cf69e498d","placeholder":"​","style":"IPY_MODEL_0b68c6c126c447759efd632a8a53e337","value":" 3/3 [00:00&lt;00:00, 104.31it/s]"}},"74e68d04a30d4b939ac20d3fc51f4696":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a323efd600c4f2ba59cd8c8c7141a95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fab6cfa3afbf49dfba3922d3ea3425f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f53c5708f3e34e46a714557c2e5eb4fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56c8caab6d3b4a81a8e4cebe01ce63a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3e986a9588c4ef39b672d8cf69e498d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b68c6c126c447759efd632a8a53e337":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b57716a3f500442b921a5e7171be91a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c6a7688e1f641a1b57806b1bfc4185f","IPY_MODEL_07ec3ee1e08a42019bff34e50ec2a8fb","IPY_MODEL_b6e750d57d0a4bcc8dada03052c70073"],"layout":"IPY_MODEL_ec700bbf04dd49729dda87dc06960899"}},"9c6a7688e1f641a1b57806b1bfc4185f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_708ee297d08342a8a7875bb234fbebbf","placeholder":"​","style":"IPY_MODEL_441162e58b7f4933aecec48b7f62bfad","value":"Extracting data files: 100%"}},"07ec3ee1e08a42019bff34e50ec2a8fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9351e0894d61487d94fc1ed6c7a8addd","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e623707c6964a83a3b4aa58fb80f5ce","value":3}},"b6e750d57d0a4bcc8dada03052c70073":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63d787e019044b78b566b10253cbd5ac","placeholder":"​","style":"IPY_MODEL_b9c7e816ea414cf99bc47c9f10098c9b","value":" 3/3 [00:00&lt;00:00, 96.94it/s]"}},"ec700bbf04dd49729dda87dc06960899":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"708ee297d08342a8a7875bb234fbebbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"441162e58b7f4933aecec48b7f62bfad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9351e0894d61487d94fc1ed6c7a8addd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e623707c6964a83a3b4aa58fb80f5ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63d787e019044b78b566b10253cbd5ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9c7e816ea414cf99bc47c9f10098c9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a14f0e4c81b14ff9bc84759d6d42e6d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ae7e6bab912491f8616a96b8090858f","IPY_MODEL_ee734698a67d4fb5ba1db56eb55e7f41","IPY_MODEL_bbac0075b6b040e6b1756a0e409e461b"],"layout":"IPY_MODEL_51c34cfd104e4d8f8b53f076ecc0b1e1"}},"5ae7e6bab912491f8616a96b8090858f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f976b04f0d4a4a8b412530a738043a","placeholder":"​","style":"IPY_MODEL_8e207d86bc5c4826a71c55fd8f4a1090","value":"Generating train split: "}},"ee734698a67d4fb5ba1db56eb55e7f41":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_073e4f9f6189407cb80c0f759b7a787b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab0a4a85926b41cbbc750f92288b46cf","value":0}},"bbac0075b6b040e6b1756a0e409e461b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28d46a3b50e843729974fdadb93048c0","placeholder":"​","style":"IPY_MODEL_a4b96b1e7c794bdeb2039cd23c5cafd3","value":" 0/0 [00:00&lt;?, ? examples/s]"}},"51c34cfd104e4d8f8b53f076ecc0b1e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5f976b04f0d4a4a8b412530a738043a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e207d86bc5c4826a71c55fd8f4a1090":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"073e4f9f6189407cb80c0f759b7a787b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ab0a4a85926b41cbbc750f92288b46cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28d46a3b50e843729974fdadb93048c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4b96b1e7c794bdeb2039cd23c5cafd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}